# Sleep Mode for YouTube -- 产品设计文档

## 1. 问题

### 用户在雇佣这个产品做什么？

> "我想听着 YouTube 入睡，但不被音频吵醒。"

每天晚上有数百万人把 YouTube 当作助眠工具 -- 播客、有声书、冥想引导、ASMR、雨声、lo-fi 音乐。他们不是在看，而是闭着眼、躺在床上、在黑暗中听。他们的大脑正在从清醒过渡到昏沉再到入睡。

但 YouTube 的音频是为相反的状态设计的：最大程度的参与感、最大程度的注意力留存。这在内容平台和用户实际场景之间制造了根本性的错位。

### 挣扎时刻

通过用户调研（Reddit r/sleep、r/podcasts、r/asmr，YouTube 评论区，睡眠 App 评价，论坛讨论），我们梳理了用户被打断的具体时刻：

| 时刻 | 发生了什么 | 用户反应 | 严重程度 |
|------|-----------|---------|---------|
| 音量跳变 | 自动播放的下一个视频音量完全不同，或者广告音量是内容的 2 倍 | 从半梦半醒中被惊醒，摸索手机调音量 | 严重 |
| 突发声音 | 笑声罐头、掌声、咳嗽、音效比对话音量高 10-15dB | 完全清醒，心率飙升，睡眠周期归零 | 严重 |
| 背景音乐渐强 | 片头/片尾音乐或背景配乐逐渐盖过说话者的声音 | 听不清在说什么，烦躁，放弃 | 高 |
| 语速过快 | 说话者语速达到自然语速的 1.2-1.5 倍（剪辑过的 YouTube 内容常见） | 昏沉的大脑跟不上，产生焦虑而非放松 | 中 |
| 声音刺耳 | 高频声音或齿音在夜间安静的房间里听着尖锐刺耳 | 不适，切换到其他内容 | 中 |

这些不是功能需求，而是不自主的生理反应 -- 肾上腺素、惊跳反射、皮质醇释放。再好的 UI 也解决不了一个在 10 毫秒内飙升 15dB 的音频信号。

### 量化验证

我们用 **100 个真实用户痛点案例** 验证了这些挣扎时刻，来源覆盖 Reddit（r/sleep、r/podcasts、r/asmr）、Hacker News、YouTube 评论区、睡眠 App 评价和各类论坛讨论。每个案例从 9 个维度评分：严重程度、痛点分类、技术可解决性、方案匹配度、睡眠相关性、影响范围、内容类型、用户情绪、发生频率。完整交互式可视化：[`docs/research/用户痛点分析可视化.html`](docs/research/用户痛点分析可视化.html)。

**痛点分布：**

| 类别 | 案例数 | 占比 | 我们的覆盖 |
|------|-------|------|-----------|
| 音量问题（跳变、尖峰、不一致） | 31 | 31% | 完全解决：标准化器 + 压缩器 + 限制器 |
| 音频质量（背景音乐、噪音、失真） | 22 | 22% | 部分解决：人声分离 + EQ |
| 平台功能（自动播放、UI） | 16 | 16% | 超出范围 |
| 广告（打断、音量） | 11 | 11% | 音量已解决（标准化器）；内容需要 Premium |
| 语音问题（语速、音调、风格） | 10 | 10% | 部分解决：播放速率 + EQ |
| 技术问题（蓝牙、缓冲） | 6 | 6% | 超出范围 |
| 内容问题（质量、相关性） | 4 | 4% | 超出范围 |

**关键指标：**

- **36% 的案例**（36/100）与我们的产品完美或高度匹配
- **53% 的案例**（53/100）我们能不同程度地解决
- **51% 的案例**（51/100）与睡眠场景直接或高度相关
- **79% 的案例**（79/100）是普遍或常见问题（非边缘情况）
- **48% 的案例**（48/100）是 P0（导致惊醒）或 P1（严重影响睡眠）

**痛点到功能的映射（我们能很好解决的 36 个案例）：**

| 痛点 | 案例数 | 对应功能 | 技术方案 |
|------|-------|---------|---------|
| 广告/视频音量跳变 | 15 | 标准化器 | BS.1770 LUFS 测量，3 秒窗口，1dB/s 速率 |
| 视频内音量波动 | 10 | 压缩器 | 快速 RMS (100ms)，6:1 比率，软拐点 |
| 突发响声 | 6 | 限制器 + 真峰值 | 前瞻峰值限制 + 4x 过采样真峰值 |
| 背景音乐盖过人声 | 7 | 人声增强 | STFT 中/侧频谱掩蔽，2048 点 FFT |
| 高频刺耳 | 2 | Sleep EQ | 6kHz 高频搁架衰减，-4dB |
| 语速过快 | 2 | 速度控制 | 原生 playbackRate=0.94, preservesPitch=false |

**我们解决不了的（47 个案例）：** 平台功能（自动播放、推荐）、广告内容本身、内容创作质量（TTS 合成语音、剪辑风格）、系统级技术问题（蓝牙断连、缓冲）。我们对这些边界保持透明 -- Sleep Mode 是实时音频 DSP 方案，不是平台包装器。

**用户情绪状态：** 47% 表达无奈（"我知道有这个问题但我没办法"），26% 困惑，12% 愤怒，10% 恐惧。无奈情绪的普遍性验证了产品假设：用户尝试过解决但失败了，因为没有现有工具直接操作音频信号本身。

### 核心洞察

五个挣扎时刻全部是**音频信号处理问题**。解决方案必须直接操作音频波形本身，实时的，逐采样的。音量滑块、睡眠定时器、"夜间模式"配色方案都是表面文章 -- 它们触碰不到波形。

### 为什么是现在

三个汇聚因素让现在成为正确的时机：

1. **AudioWorklet 成熟**（2023-2024）：Chrome 的 AudioWorklet API 已经稳定且高性能。它提供专用音频处理线程，每个块有 2.67ms 的时间预算。两年前这个 API 还有跨浏览器 bug 和性能问题，生产级 DSP 不现实。

2. **Manifest V3 稳定**（2024）：Chrome 从 MV2 到 MV3 的扩展平台迁移已完成。现在构建于 MV3 意味着没有迁移风险。MV3 的 `web_accessible_resources` 功能允许 AudioWorklet 脚本从扩展上下文干净地加载。

3. **没有人解决过这个问题**：尽管 YouTube 月活 27 亿、睡眠是后台音频的第一大使用场景，没有任何产品直接处理音频信号本身。每个现有的"睡眠"方案都是包装器（定时器、调光器、播放列表），原始音频原封不动。

## 2. 竞争格局

### 真正的竞争对手是现状

大多数用户不使用任何工具。他们只是"凑合" -- 把音量调低到最响的部分不会吵醒自己的程度，代价是安静的部分就听不到了。这是我们要竞争的主要行为。

| 现有解决方案 | 用户怎么做 | 为什么失败 |
|-------------|-----------|-----------|
| 把音量调到最低安全水平 | 设定音量使最响的时刻不会惊醒自己 | 安静部分变得听不见；漏掉内容 |
| 设置睡眠定时器 | YouTube/手机定时器在 N 分钟后停止播放 | 在聆听期间没有帮助；糟糕的音频照样播放 |
| 切换到"更温和"的内容 | 避开有广告/音乐的播客，只播环境音 | 大幅限制内容选择；用户不应该需要预先筛选 |
| 改用白噪声 App | 完全放弃 YouTube，转用 Calm/Headspace/雨声 App | 失去了他们喜欢的内容（特定播客、特定创作者） |
| 手动均衡器 App | 安装系统 EQ App，每个视频手动调节 | 需要技术知识，不处理动态范围，不了解 LUFS |

### 相邻产品

| 产品 | 它做什么 | 它不做什么 |
|------|---------|-----------|
| YouTube Premium | 去广告、后台播放 | 零音频处理。音量跳变、瞬态、背景音乐原封不动 |
| 睡眠定时器 App | N 分钟后停止播放 | 完全不修改音频 |
| Calm / Headspace | 精选睡眠音频库 | 只有自己的内容；不能用你的 YouTube 订阅 |
| 系统均衡器 (EQualizer+, Boom) | 频率调整 | 没有响度标准化、没有瞬态保护、没有人声分离。静态 EQ 无法响应动态内容 |
| 浏览器音量扩展 | 设置每个标签页音量 | 音量就是一个数字；不解决内容内部的动态范围问题 |

### 我们的不对称优势

没有现有产品能在元素级别拦截 YouTube 的音频流并用自定义 DSP 实时处理。这需要三种能力同时具备，但它们不存在于任何其他地方：

1. **对 `<video>` 元素的 DOM 访问** -- 只有 Chrome 内容脚本能做到
2. **带 AudioWorklet 的 Web Audio API** -- 只在现代浏览器中可用，原生 App 做不到
3. **领域特定 DSP 知识** -- 知道"适合睡眠的音频"在声学上意味着什么（目标 LUFS、压缩比、频率曲线、起音时间）

这个组合在结构上难以被复制：YouTube 自己不会做（他们优化的是参与度，不是睡眠），睡眠 App 做不到（它们无法访问 YouTube 的音频），通用均衡器扩展也做不到（它们缺乏多级动态处理能力）。

## 3. 设计信条

按优先级排序。当信条冲突时，排名高的胜出。

1. **永远不打扰睡眠。** 音频只能变得更安静、更柔和，绝不能变得更响或更刺耳。如果一个处理环节有可能增加响度，它就不上线。这是硬约束，不是偏好。

2. **零配置。** 用户点一个按钮，其他一切自动。没有滑块、没有阈值、没有"高级设置"。预设编码了我们的领域知识，用户不需要具备任何知识。

3. **默认正确。** 默认预设（Sleep）必须在最常见的场景（听着播客入睡）下无需调整就能良好工作。存储默认值、初始状态、所有参数都必须精确匹配默认预设。

4. **透明处理。** 音频应该听起来自然，不像被处理过。没有可感知的抽吸感、呼吸感或伪影。如果你能听出压缩器在工作，说明参数不对。

5. **最小占用。** 零运行时依赖。不用 React，不用框架。总包体积低于 50KB。AudioWorklet 线程处理 DSP；主线程保持空闲。扩展在 CPU/内存使用上应该是隐形的。

## 4. 产品形态决策

### 权衡矩阵

| 标准 | 权重 | Chrome 扩展 | 桌面应用 (Tauri) | 移动应用 | Web 应用 |
|------|------|------------|----------------|---------|---------|
| 直接访问 YouTube 音频 | 必须 | 直接访问 `<video>` 元素 | 系统音频捕获（间接） | iOS/Android 上不可能 | 不可能（CORS） |
| 实时 DSP 能力 | 必须 | AudioWorklet（专用线程） | 原生音频管线（WASAPI/CoreAudio） | 有限（后台处理限制） | AudioWorklet（与扩展相同） |
| 安装摩擦 | 高 | 一键（Chrome 网上应用店） | 下载+安装+权限 | 应用商店+审核周期 | 零（但无法访问 YouTube 音频） |
| 跨平台 | 中 | 仅 Chrome（覆盖约 65% 桌面浏览器份额） | macOS+Windows（独立代码库） | iOS+Android（独立代码库） | 所有浏览器 |
| 开发复杂度 | 中 | 单一代码库，Web 技术 | Rust+平台特定音频驱动 | 每个平台原生 | 与扩展相同，减去分发 |
| 维护负担 | 中 | 一个代码库 | 两个平台音频层，对 OS 更新敏感 | 两个平台，应用商店审核 | 一个代码库 |

**决策：Chrome 扩展。**

Chrome 扩展是唯一同时提供「直接访问 YouTube 音频」和「零安装摩擦」的产品形态。桌面应用（Tauri）是我们的第二选择，我们也构建了可工作的原型 -- 它能用，但平台特定音频捕获的复杂度（macOS 上的 CoreAudio ScreenCaptureKit 权限、Windows 上的 WASAPI loopback）为相同的最终结果增加了 10 倍的开发面积。

### 我们放弃了什么

- **非 Chrome 浏览器**：Firefox/Safari 用户无法使用。Firefox 的 AudioWorklet 支持有限，Safari 的扩展模型不同。我们接受这个权衡，因为 Chrome 占约 65% 桌面浏览器市场份额，YouTube 使用量重度偏向 Chrome。
- **移动端**：YouTube 移动用户无法使用。移动操作系统不允许扩展修改 App 音频。如果移动端变得关键，需要一个带自己音频播放器的独立 App（不修改 YouTube）。
- **非 YouTube 来源**：Spotify、Apple Podcasts 等不在覆盖范围内。扩展只在 youtube.com 和 music.youtube.com 上工作。系统级音频捕获（桌面应用路径）才能实现通用来源支持。

## 5. 方案架构

### 信号链

处理管线是一个**分层防御系统**。每一层在不同的时间尺度上运作，捕获前一层太慢（或太快）而无法处理的内容：

```
YouTube <video> 元素
    |
    video.playbackRate = 0.94, preservesPitch = false
    |   (原生 C++ 重采样器：减缓语速，降低音调)
    |   (解决：语速过快、音调刺耳)
    |
    MediaElementSourceNode
    |
    [1] 人声分离器 (AudioWorklet)
    |     STFT 中/侧分解，2048 点 FFT，50% 重叠
    |     频带频谱掩蔽：80-300Hz 渐入，
    |     300-3400Hz 人声频带，3400-8000Hz 渐出
    |     衰减背景音乐，保留语音
    |     启用/禁用时 10ms 交叉淡化
    |     解决：背景音乐盖过说话者
    |
    [2] 高通滤波器 (BiquadFilterNode, 80Hz, Q=0.707)
    |     去除次低频隆隆声和直流偏移
    |
    [3] 三段 EQ (BiquadFilterNode x3)
    |     低频搁架 (200Hz) + 峰值 (3kHz) + 高频搁架 (6kHz)
    |     按预设进行频率塑形
    |     解决：高频刺耳
    |
    [4] 响度标准化器 (AudioWorklet) -- 时间尺度：3 秒
    |     BS.1770-4 K 加权 LUFS 测量
    |     3 秒滑动窗口，100ms 更新间隔
    |     最大增益变化速率 1 dB/s（防止可感知的音量跳变）
    |     条件性增益提升：仅在低于 -35 LUFS 时，最大 +3dB
    |     -60 LUFS 静音门限
    |     解决：视频间和视频内的音量不一致
    |
    [5] 快速 RMS 压缩器 (AudioWorklet) -- 时间尺度：100ms
    |     滑动窗口 RMS 测量（100ms 窗口）
    |     15ms 起音，400ms 释放
    |     软拐点（6dB）二次插值
    |     按预设压缩比：3:1（温和）到 6:1（激进）
    |     仅衰减增益，绝不增益
    |     解决：突发笑声、掌声、咳嗽、音效
    |
    [6] 前瞻峰值限制器 (AudioWorklet) -- 时间尺度：5ms
    |     5ms 前瞻延迟缓冲
    |     1ms 起音，50ms 释放
    |     硬天花板 -3 dBFS，带安全硬削波
    |
    [7] 真峰值限制器 (AudioWorklet) -- 时间尺度：亚采样
    |     4x 线性插值过采样
    |     捕获采样级限制器遗漏的采样间峰值
    |     安全天花板 -2 dBTP
    |
    [8] 主增益 (GainNode)
    |     按预设音量偏移（-3 到 -6 dB）
    |
    AudioContext.destination
```

### 为什么需要 4 层增益控制（并非冗余）

| 层 | 时间尺度 | 捕获什么 | 举例 | 为什么其他层做不到 |
|---|---------|---------|------|------------------|
| 标准化器 | 3 秒 | 曲目间响度差异：播客 A 是 -16 LUFS，播客 B 是 -22 LUFS | 自动播放从响的视频切到安静的视频 | 压缩器/限制器响应瞬态，不是长期平均 |
| 压缩器 | 100ms | 曲目内的突发响度事件：笑声、咳嗽、掌声 | 脱口秀主持人的段子引发 12dB 的观众笑声 | 标准化器太慢（3s 窗口，1dB/s 速率）；限制器基于峰值，不基于响度 |
| 限制器 | 5ms | 采样级幅度峰值超过 -3dBFS | 拍手产生 0dBFS 瞬态 | 没有感知响度意识；不能测量 LUFS |
| 真峰值 | 亚采样 | 数模转换重建产生的采样间峰值 | 两个连续采样在 -1dBFS 可以在它们之间重建为 +2dBFS | 采样级限制器只看离散采样，看不到连续波形 |

### 关键技术决策

**为什么不用 DynamicsCompressorNode**

Web Audio API 提供了内置的 `DynamicsCompressorNode`。我们故意不用它。它有无法禁用的自动补偿增益 -- 压缩一个响的声音之后，它会增益输出来补偿，这直接违反了信条 #1（"绝不更响"）。我们的自定义 Worklet 压缩器只做增益衰减。

**为什么标准化器测量原始输入而非输出**

LUFS 测量在 K 加权的输入信号上进行。增益调整施加于原始（未加权）信号。如果我们测量输出（增益后），标准化器会看到自己的增益变化并进入反馈回路 -- 它把声音调小，测量到更安静，又调大，测量到更响，无限循环。

**为什么用原生变调而非 DSP 算法**

我们探索过 WSOLA（波形相似重叠相加）时间拉伸 + 重采样来实现独立的速度/音调控制。问题是：AudioWorklet 以 128 采样块处理（48kHz 下 2.67ms）。WSOLA 需要约 2400 采样的分析窗口（50ms）。算法粒度和 Worklet 块大小之间的根本性错位产生了可听的伪影 -- 电噪声、咔嗒声和音调失真。

解决方案：`video.playbackRate = 0.94` 配合 `video.preservesPitch = false`。浏览器委托给其原生 C++ 音频重采样器，它在比 Web Audio 图更低的层级运作。零伪影，零 CPU 开销。速度和音调的耦合对于睡眠来说是特性 -- 慢 6% + 略低音调 = 更温暖、更舒缓。

**为什么用软拐点压缩**

硬拐点压缩器产生可听的"抽吸"效果：信号一过阈值，压缩就突然启动。我们的软拐点（6dB）在拐点区域使用二次插值：

- 低于阈值 -3dB：不压缩（0 dB 增益变化）
- 阈值 -3dB 到阈值 +3dB：渐进的二次曲线起始
- 高于阈值 +3dB：完全比率压缩

这使压缩不可感知 -- 信号变安静了但听众感觉不到动态处理器在工作。对信条 #4（"透明处理"）至关重要。

**为什么条件性增益提升有 -35 LUFS 门限**

标准化器的默认模式是仅衰减（信条 #1）。但真正安静的内容（-40 LUFS 的 ASMR 耳语）会被保持在听不到的水平。`boostBelowLufs = -35` 允许最多 +3dB 增益，但仅限于低于 -35 LUFS 的内容。正常内容（-24 到 -16 LUFS 范围）只能被衰减。下游的限制器和真峰值限制器作为安全网提供硬天花板。

## 6. 预设设计

### 内容类别与用户行为聚类

用户不用音频工程术语描述他们听的内容。他们说"我听播客入睡"或"我放雨声"。我们按**聆听行为**聚类，而非内容类型：

| 行为聚类 | 内容举例 | 关键音频特征 | 用户需要什么 |
|---------|---------|------------|------------|
| 以人声为中心的睡眠 | 播客、有声书、冥想引导、讲座 | 语音伴随变化的背景音乐/音效 | 隔离人声、压制音乐、减速、温暖音色 |
| 以纹理为中心的睡眠 | ASMR 耳语、敲击、抓挠、掏耳 | 非常安静，高频细节就是内容本身 | 保留全频谱、一致的安静音量、不做滤波 |
| 以信息为中心的睡眠 | 脱口秀、访谈、辩论、新闻 | 多人说话、动态变化大、偶尔的大声反应 | 最大化语音清晰度、压缩动态、减少浑浊 |
| 环境音睡眠 | 雨声、海浪、风扇、炉火、lo-fi 音乐 | 稳态、无语音、无瞬态 | 最少处理、保留频谱特性、防止漂移 |

### 预设参数

| 预设 | 目标 LUFS | 压缩器 | 速度 | 人声分离 | EQ | 主增益 |
|-----|----------|--------|-----|---------|-----|-------|
| **Sleep** | -26 | 6:1 比率, -24dB 阈值, 15ms 起音 | 0.94x | 开启：音乐 -6dB | 温暖：高频搁架 -4dB @ 6kHz | -6dB |
| **ASMR** | -28 | 6:1 比率, -26dB 阈值, 15ms 起音 | 1.0x | 关闭 | 平坦（全频段 0dB） | -6dB |
| **Podcast** | -24 | 3:1 比率, -20dB 阈值, 20ms 起音 | 0.94x | 开启：人声 +3dB, 音乐 -6dB | 清晰：低频搁架 -3dB @ 300Hz | -3dB |
| **White Noise** | -26 | 3:1 比率, -22dB 阈值, 20ms 起音 | 1.0x | 关闭 | 关闭 | -3dB |

**响度梯度：** ASMR (-28) < Sleep/WhiteNoise (-26) < Podcast (-24)

**每个预设的设计理由：**

- **Sleep** 是默认且最激进的预设。-26 LUFS 比 YouTube 典型的 -16 LUFS 平均值低 10dB -- 感知响度降低约 3 倍。6:1 压缩比意味着 12dB 的突发尖峰变成 2dB 的小波动。人声分离开启以压制与说话者竞争的片头/片尾音乐和背景配乐。0.94x 速度使语速慢 6% 且音调略低，匹配昏沉大脑处理语言的速率。

- **ASMR** 有最低的目标（-28 LUFS），因为 ASMR 内容本身就很安静，听众期望接近静默。压缩器激进（6:1）以捕获任何大声的触发音（某些 ASMR 创作者包含突然的敲击声），但阈值更低（-26dB），只在真正的尖峰时激活。EQ 平坦因为 ASMR 依赖高频纹理 -- 衰减高频会毁掉内容。不改变速度因为 ASMR 的节奏是体验的一部分。

- **Podcast** 优先考虑语音清晰度。-24 LUFS 是最响的预设，但仍比典型 YouTube 低 8dB。人声分离主动增强人声（+3dB）同时减弱音乐（-6dB）。压缩更温和（3:1，20ms 起音）以保留自然的语音动态 -- 3:1 比率仍能捕获笑声罐头但不会让主持人听起来像机器人。低频搁架衰减（300Hz -3dB）减少通过枕头/耳塞听时让语音变得不清晰的"浑浊"中低频。

- **White Noise** 施加最少的处理。EQ 关闭以保留雨声、海浪或风扇声的频谱特性（均衡白噪声会改变它的"颜色"）。轻度压缩（3:1）防止长时间环境录音的渐进音量漂移。不开人声分离因为没有人声需要分离。

## 7. 用户体验

### 前 30 秒（"顿悟时刻"）

产品的顿悟时刻是听到差异。用户必须在安装扩展后 30 秒内体验到处理后的音频：

```
第 0 秒：  用户从 Chrome 网上应用店安装扩展
第 3 秒：  扩展图标出现在工具栏
第 5 秒：  用户已经在一个 YouTube 视频上（最可能的场景）
第 8 秒：  用户点击扩展图标，弹窗打开
第 10 秒： 用户看到电源按钮和"Tap to activate"标签
第 12 秒： 用户点击电源按钮
第 12 秒： 音频处理立即激活：
           - 音量标准化到 -26 LUFS
           - 压缩器开始捕获瞬态
           - 人声分离减弱背景音乐
           - 播放减速至 0.94x，音调下降
           - 温暖 EQ 衰减高频
第 15 秒： 用户立即听到差异
```

**关键设计选择：** 我们不展示引导轮播、教程、"选择你的预设"向导或"了解我们的功能"页面。弹窗打开就是一个电源按钮。点它。听到差异。这就是入门引导。

### 为什么用预设而非滑块

用户不知道什么是"压缩比"。他们不知道"LUFS"什么意思。他们不知道"高频搁架滤波器"在什么频率上工作。暴露这些控件会：

1. 迫使用户做他们没有能力做的决定
2. 制造关于设置是否"正确"的焦虑
3. 产生比我们预调的预设更差的结果（用户设置 20:1 压缩比会听起来很糟糕）

预设模型编码了我们的领域专长。用户唯一的决策是"我在听什么？" -- 四个预设覆盖了主要类别。即使这个决策也是可选的，因为默认的（Sleep）适用于最常见的使用场景。

### 状态管理

- 所有设置持久化在 `chrome.storage.sync`（跨 Chrome 实例同步）
- 默认状态精确匹配 Sleep 预设：`enabled: false, presetId: "sleep", masterGainDb: -6.0, eqEnabled: true, vocalEnhance: true`
- 切换预设原子性地更新所有参数 -- 不存在部分状态
- YouTube SPA 导航透明处理：当 YouTube 不完全刷新页面就切换视频时，管线保持连接

## 8. 范围与非目标

### 已发布的内容（v1）

- 实时音频处理（8 级信号链）
- 4 个内容感知预设（Sleep、ASMR、Podcast、White Noise）
- 一键启用/禁用
- 实时 LUFS + 增益衰减 + 输入峰值仪表
- 支持 youtube.com 和 music.youtube.com
- 跨会话设置持久化

### 我们刻意砍掉的

| 被砍功能 | 为什么砍 | 什么时候重新考虑 |
|---------|---------|---------------|
| 逐参数滑块（阈值、比率、EQ 频段） | 违反信条 #2（零配置）。用户调不出比我们更好的 DSP 参数。 | 用户调研显示高级用户需要自定义预设 |
| 睡眠定时器 | YouTube 已经有了。重复它增加复杂度但零独特价值。 | 如果 YouTube 移除了他们的 |
| 入睡前渐弱 | 需要预测用户什么时候入睡 -- 我们做不到。固定定时器是猜测。 | 如果我们添加生物识别集成（智能手表心率） |
| Firefox / Safari 支持 | Firefox AudioWorklet 不太稳定。Safari 扩展模型不同。市场份额不足以证明投入合理。 | 当 Firefox AudioWorklet 稳定或用户需求被证明 |
| 广告感知处理 | 检测 YouTube 广告并应用不同处理。 | 如果我们能不依赖 YouTube API 可靠地检测广告边界 |
| 自定义预设创建 | 没有音频工程知识的用户无法正确调整 DSP 参数。 | 如果我们设计一个将用户语言翻译为 DSP 参数的引导式"向导" |
| 可视化（频谱分析仪、波形） | 增加 CPU 开销，分散睡眠场景注意力，违反"最小占用"信条。 | 如果我们构建单独的"监视器"模式用于调试 |

### V2 候选（未承诺）

- 多活动预设配置文件（按时间段切换）
- YouTube Music 深度集成
- 按频道（创作者）记忆预设
- 启用/禁用键盘快捷键
- 配套移动应用（自有音频播放器，不修改 YouTube）

## 9. 成功标准

### Sean Ellis 测试框架

如果我们调查活跃用户"如果你不能再使用 Sleep Mode for YouTube，你会有什么感受？"：

- **目标：40%+ 回答"非常失望"**
- 如果低于 40%：音频处理没有产生足够可感知的差异，或目标受众不对
- 如果高于 40%：我们在这个细分市场达到了产品市场契合

### 量化指标

| 指标 | 衡量什么 | 目标 |
|------|---------|------|
| 日活（DAU）/ 周活（WAU） | 留存：人们会回来吗？ | DAU/WAU > 0.5（一周中超过一半的天数在使用） |
| Sleep Mode 开启的平均会话时长 | 参与度：他们实际使用多长时间？ | > 30 分钟（足够入睡） |
| 预设分布 | 我们的 4 个预设是否覆盖了实际使用场景 | 没有单个预设 > 80%（否则其他预设无用） |
| 扩展卸载率（30 天） | 满意度：他们会保留吗？ | 30 天内 < 20% 卸载 |
| Chrome 网上应用店评分 | 公开满意度信号 | > 4.5 星 |

### 质性信号

- 用户把扩展描述为"我现在没它睡不着"（依赖 = PMF）
- 用户不被提示就推荐给别人（自然口碑传播）
- 功能请求是关于扩展的（"你们能支持 Spotify 吗？"），而非修复核心体验

## 10. 风险与应对

| 风险 | 可能性 | 影响 | 应对 |
|------|-------|------|------|
| YouTube 改变 `<video>` 元素结构 | 低（多年稳定） | 高（打破音频捕获） | YouTubeObserver 使用 MutationObserver 带回退选择器。可通过扩展更新适应 DOM 变化。 |
| Chrome 废弃或限制 `MediaElementAudioSourceNode` | 非常低 | 致命 | Chrome 团队无此信号。这是核心 Web Audio API。 |
| AudioWorklet 在低端硬件上性能下降 | 中 | 中 | 所有处理都是 O(n) 每采样。128 采样 @ 48kHz = 2.67ms 预算。我们的处理在中端硬件上实测约 0.5ms。5 倍余量。 |
| 用户感知到音质下降 | 中 | 高 | 软拐点压缩 + 慢标准化器速率（1dB/s）+ 透明设计信条。如果用户注意到处理，参数需要调优。 |
| YouTube Premium 用户期望"开箱即用" | 低 | 低 | 扩展有无 Premium 都能工作。Premium 去广告但不改变音频处理 -- 它们是互补的。 |
| 竞争对手复制此方案 | 低（需要 DSP 专长） | 中 | 我们的不对称优势是信号链设计，不是单一功能。复制 4 层增益控制 + 人声分离 + 按预设调校需要通用扩展开发者不具备的领域专长。 |

## 11. 架构与构建

### 扩展架构

```
manifest.json (MV3)
  |
  +-- Background Service Worker (ESM)
  |     纯消息路由器，连接 popup 和 content script。
  |     不处理音频，不保存状态。
  |
  +-- Content Script (IIFE)
  |     运行在 YouTube 页面上下文中。
  |     拥有 Web Audio 管线生命周期。
  |     YouTubeObserver：用于 SPA 导航的 MutationObserver。
  |     状态机：启用/禁用、预设切换、旁通。
  |
  +-- AudioWorklet 处理器 (IIFE, 专用音频线程)
  |     sleep-processor.ts: 标准化器 + 压缩器 + 限制器 + 真峰值
  |     vocal-processor.ts: FFT + 频谱掩蔽人声分离
  |     各自在独立线程中运行，128 采样块，48kHz。
  |
  +-- Popup (IIFE)
        无状态控制面板。
        所有状态来自 chrome.storage.sync。
        来自 content script 的实时 LUFS/增益衰减仪表。
```

### 构建系统

- **esbuild**：亚秒级构建。每个入口点独立打包（content script 和 worklet 用 IIFE，service worker 用 ESM）。
- **TypeScript**：严格模式。共享类型在 `src/shared/types.ts` 中定义一次，由 esbuild 内联到每个包中。
- **无框架**：原生 TypeScript + HTML/CSS。零运行时依赖。总包体积 < 50KB。
- **预构建 dist**：`dist/` 文件夹已提交，扩展可以无需构建步骤直接加载。

### 文件结构

```
sleep-mode-extension/
  manifest.json              # Chrome 扩展清单 (V3)
  package.json               # 仅开发依赖 (esbuild, typescript)
  build.config.ts            # esbuild 多入口配置
  tsconfig.json              # TypeScript 严格模式配置
  src/
    shared/
      types.ts               # 所有类型定义（管线、预设、仪表、存储）
      constants.ts            # 4 个预设配置含完整参数集
      storage.ts              # chrome.storage.sync 加载/保存/变更监听
      messages.ts             # 消息类型定义和类型守卫
    content/
      content-script.ts       # 管线生命周期、状态管理、消息处理
      audio-pipeline.ts       # Web Audio 图构建和控制
      youtube-observer.ts     # YouTube SPA 导航 MutationObserver
    worklet/
      sleep-processor.ts      # 780 行：K 加权、标准化器、压缩器、限制器、真峰值
      vocal-processor.ts      # 395 行：FFT、STFT、频谱掩蔽、重叠相加
    background/
      service-worker.ts       # 消息路由（popup <-> content script）
    popup/
      popup.ts                # 控制面板逻辑
      popup.html              # 弹窗标记
      popup.css               # 弹窗样式
  dist/                       # 预构建输出（可直接加载到 Chrome）
  assets/icons/               # 扩展图标 (16, 48, 128px)
```

## 10. 桌面版探索

在构建 Chrome 扩展之前，我们探索了 **跨平台桌面方案**，使用 Tauri（Rust + React）在操作系统层面捕获系统音频。桌面版作为独立仓库发布：**[sleep-mode-desktop](https://github.com/Yida-Dev/sleep-mode-desktop)**。

### 我们学到了什么

桌面原型用 8 级纯 Rust DSP 管线（4400+ 行，无外部 DSP 库）验证了我们的 DSP 架构：人声分离器、前瞻限制器、RMS 压缩器、响度标准化器、睡眠 EQ、时间拉伸、音调变换、真峰值限制器。关键技术成果：

- **WSOLA 时间拉伸**，支持独立的速度/音调控制（浏览器 AudioWorklet 的 128 采样块中无法实现）
- **组合式变调**：时间拉伸 + 重采样，优雅的模块复用而非专用算法
- **无 ML 人声分离**：STFT 频谱掩蔽，<1KB 代码，<5ms 延迟
- **macOS Core Audio Taps**（14.2+）：无需虚拟驱动的系统音频捕获
- **总延迟低于 10ms**，通过 8 级管线全链路单元测试验证

### 为什么扩展胜出

桌面应用需要系统级音频捕获（macOS 的 CoreAudio Taps、Windows 的 WASAPI Loopback + VB-CABLE），带来显著的安装摩擦和未解决的权限问题。Chrome 扩展通过直接访问 `<video>` 元素实现零权限需求，用 DSP 能力换取简洁性 -- 对「YouTube 音频助眠」这个场景来说，这是正确的权衡。

### 未来

Rust DSP 模块已达到生产就绪状态。如果我们扩展到非浏览器音频（Spotify、Apple Music），桌面管线随时可以投入使用。
